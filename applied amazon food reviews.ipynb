{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import nltk                                         #Natural language processing tool-kit\n",
    "\n",
    "from nltk.corpus import stopwords                   #Stopwords corpus\n",
    "from nltk.stem import PorterStemmer                 # Stemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer          #For Bag of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer          #For TF-IDF\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('C:\\\\Users\\\\krishna\\\\Downloads\\\\Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1908575fd30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.\n",
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in our data (568454, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      1  1303862400   \n",
       "1                     0                       0      0  1346976000   \n",
       "2                     1                       1      1  1219017600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#changing reviews with score less than 3 to be negative and vice-versa\n",
    "actualScore = df['Score']\n",
    "positiveNegative = actualScore.map(partition) \n",
    "df['Score'] = positiveNegative\n",
    "print(\"Number of data points in our data\", df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1.drop_duplicates(subset=['Id','ProductId','ProfileName','Time','Score','Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      1  1303862400   \n",
       "1                     0                       0      0  1346976000   \n",
       "2                     1                       1      1  1219017600   \n",
       "3                     3                       3      0  1307923200   \n",
       "4                     0                       0      1  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df2[df2['HelpfulnessNumerator']<=df2['HelpfulnessDenominator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8478\n",
       "0    1522\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df3['Text']\n",
    "df_y = df3['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"shan't\", 'doesn', 'hadn', \"you'll\", 'o', \"didn't\", 'than', 'has', 'shouldn', 'because', 'couldn', 'didn', 'further', 'm', 'this', 'he', 'theirs', 'am', 'from', 't', 'some', \"you've\", 'between', 'we', 'him', 'do', 'ourselves', 'down', 'how', 'through', 'on', 'such', 'these', 'both', 'have', \"weren't\", 'his', 'in', 'above', 'itself', 'which', 'isn', 'very', 'they', 'doing', 'd', \"don't\", 'what', 'are', 'a', \"doesn't\", 'during', 'only', 'wasn', 'whom', 'and', 'against', 'below', 'all', 'if', 'other', 'each', \"mightn't\", 'our', 'any', 'that', \"shouldn't\", 'needn', 'its', 've', 'hers', 'until', 'be', 'having', 'wouldn', 'why', 'up', 'under', 'she', \"hadn't\", 'will', 'over', 'but', 'same', 'while', 'mustn', 'them', 'once', 's', 'my', 'don', 'of', 'i', 'those', 'y', 'herself', 'who', 'again', 'most', 'nor', 'themselves', \"should've\", \"it's\", \"wasn't\", \"you're\", 'does', 'own', 'hasn', 'their', 'should', 'aren', 'ain', 'by', \"couldn't\", 'had', 'before', 'your', \"won't\", 'no', 'yours', 'or', 'won', 'did', 'shan', 'yourself', \"mustn't\", 'were', 'himself', 'me', 'being', 'at', 'more', 'where', 'off', 'was', 'her', 'ours', \"you'd\", 'to', \"wouldn't\", 'just', 'haven', \"hasn't\", 'with', 'for', 'when', 'an', 'out', 'few', 'now', 'yourselves', 'here', \"she's\", 'into', 'it', 'too', 'after', 'about', 'can', 'been', 'there', 'then', \"haven't\", \"needn't\", 're', 'ma', 'the', 'as', 'so', \"that'll\", 'mightn', 'is', \"aren't\", \"isn't\", 'weren', 'not', 'myself', 'you', 'll'}\n"
     ]
    }
   ],
   "source": [
    "stop = set(stopwords.words('english')) \n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp =[]\n",
    "snow = nltk.stem.SnowballStemmer('english')\n",
    "for sentence in df_X:\n",
    "    sentence = sentence.lower()   \n",
    "    #convertinging to lowercase\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    sentence = re.sub(cleanr, ' ', sentence)        #Removing HTML tags\n",
    "    sentence = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    sentence = re.sub(r'[.|,|)|(|\\|/]',r' ',sentence)        #Removing Punctuations\n",
    "    \n",
    "    words = [snow.stem(word) for word in sentence.split() if word not in stopwords.words('english')]   # Stemming and removing stopwords\n",
    "    temp.append(words)\n",
    "    \n",
    "df_X = temp    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['product', 'arriv', 'label', 'jumbo', 'salt', 'peanut', 'peanut', 'actual', 'small', 'size', 'unsalt', 'sure', 'error', 'vendor', 'intend', 'repres', 'product', 'jumbo']\n"
     ]
    }
   ],
   "source": [
    "print(df_X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " product arriv label jumbo salt peanut peanut actual small size unsalt sure error vendor intend repres product jumbo\n"
     ]
    }
   ],
   "source": [
    "sent = []\n",
    "for row in df_X:\n",
    "    sequ = ''\n",
    "    for word in row:\n",
    "        sequ = sequ + ' ' + word\n",
    "    sent.append(sequ)\n",
    "\n",
    "df_X = sent\n",
    "print(df_X[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BINARY BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3651)\t1\n",
      "  (0, 2340)\t1\n",
      "  (0, 4730)\t1\n",
      "  (0, 1538)\t1\n",
      "  (0, 4315)\t1\n",
      "  (0, 4672)\t1\n",
      "  (0, 3984)\t1\n",
      "  (0, 4021)\t1\n",
      "  (0, 164)\t1\n",
      "  (0, 3228)\t2\n",
      "  (0, 3779)\t1\n",
      "  (0, 2429)\t2\n",
      "  (0, 2498)\t1\n",
      "  (0, 333)\t1\n",
      "  (0, 3441)\t2\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(max_features=5000)\n",
    "bow_data = count_vect.fit_transform(df_X)\n",
    "print(bow_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BI-GRAM BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_B_X = df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 155132)\t1\n",
      "  (0, 164349)\t1\n",
      "  (0, 102952)\t1\n",
      "  (0, 213144)\t1\n",
      "  (0, 66027)\t1\n",
      "  (0, 192054)\t1\n",
      "  (0, 209826)\t1\n",
      "  (0, 178486)\t1\n",
      "  (0, 179474)\t1\n",
      "  (0, 4431)\t1\n",
      "  (0, 145033)\t1\n",
      "  (0, 145079)\t1\n",
      "  (0, 169020)\t1\n",
      "  (0, 105996)\t1\n",
      "  (0, 108824)\t1\n",
      "  (0, 12959)\t1\n",
      "  (0, 154737)\t1\n",
      "  (0, 164341)\t1\n",
      "  (0, 102936)\t1\n",
      "  (0, 213127)\t1\n",
      "  (0, 66013)\t1\n",
      "  (0, 191974)\t1\n",
      "  (0, 209817)\t1\n",
      "  (0, 178220)\t1\n",
      "  (0, 179252)\t1\n",
      "  (0, 4224)\t1\n",
      "  (0, 145032)\t2\n",
      "  (0, 168871)\t1\n",
      "  (0, 105990)\t2\n",
      "  (0, 108757)\t1\n",
      "  (0, 12876)\t1\n",
      "  (0, 154681)\t2\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(1,2))\n",
    "Bigram_data = count_vect.fit_transform(df_B_X)\n",
    "print(Bigram_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3441)\t0.18202403814257867\n",
      "  (0, 333)\t0.15673405699699108\n",
      "  (0, 2498)\t0.18332702337658963\n",
      "  (0, 2429)\t0.5721373890087614\n",
      "  (0, 3779)\t0.15408086526397632\n",
      "  (0, 3228)\t0.37467426339124205\n",
      "  (0, 164)\t0.14625267770919553\n",
      "  (0, 4021)\t0.14539428502791302\n",
      "  (0, 3984)\t0.14547147340823857\n",
      "  (0, 4672)\t0.27294106253378553\n",
      "  (0, 4315)\t0.1419427154646107\n",
      "  (0, 1538)\t0.2702954366823277\n",
      "  (0, 4730)\t0.22144851953773764\n",
      "  (0, 2340)\t0.24959614137557432\n",
      "  (0, 3651)\t0.27294106253378553\n"
     ]
    }
   ],
   "source": [
    "df_tf = df_X\n",
    "tf_idf = TfidfVectorizer(max_features=5000)\n",
    "tf_data = tf_idf.fit_transform(df_tf)\n",
    "print(tf_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_data = df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted = []\n",
    "for row in w2v_data: \n",
    "    splitted.append([word for word in row.split()])     #splitting words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_w2v = Word2Vec(splitted,min_count=5,size=50, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "avg_data = []\n",
    "for row in splitted:\n",
    "    vec = np.zeros(50)\n",
    "    count = 0\n",
    "    for word in row:\n",
    "        try:\n",
    "            vec += train_w2v[word]\n",
    "            count += 1\n",
    "        except:\n",
    "            pass\n",
    "    avg_data.append(vec/count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.20866474 -0.04804418  0.33953007 -0.16589438 -0.67706675 -0.22344004\n",
      "  0.10531413  0.21572179  0.44418034 -0.37828587 -0.33229139 -0.52005218\n",
      "  0.0700564  -0.53940408  0.49824321 -0.028892   -0.21142907 -0.3126281\n",
      " -0.11368512 -0.42777478  0.27552921 -0.29041104  0.14805121  0.11626285\n",
      "  0.24275787 -0.2444412   0.09210719 -0.39878657 -0.03763622 -0.00799167\n",
      "  0.08234614 -0.08339     0.41415728 -0.10981268 -0.45579088 -0.38102163\n",
      "  0.00604516 -0.45521933  0.55935653 -0.22000632  0.17639184  0.19813541\n",
      "  0.34846662  0.19316549 -0.0219252  -0.13574463  0.0985726  -0.06597723\n",
      " -0.16895053 -0.11417216]\n"
     ]
    }
   ],
   "source": [
    "print(avg_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF WORD2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_w_data = df_X\n",
    "tf_idf = TfidfVectorizer(max_features=5000)\n",
    "tf_idf_data = tf_idf.fit_transform(tf_w_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.2975844   0.21111186  0.57845095 -0.20743652 -0.62389627 -0.57621096\n",
      " -0.01946516  0.21944995  0.5923039  -0.45637568 -0.43860161 -0.56667612\n",
      "  0.04603565 -0.47870589  0.44056394 -0.01094492 -0.16896692 -0.26091195\n",
      "  0.01596791 -0.75692239  0.31792831 -0.42898294  0.31024709 -0.00394529\n",
      "  0.24000925 -0.17044874  0.36393781 -0.2452906   0.05960905 -0.17497073\n",
      "  0.00486757  0.03416036  0.62224513 -0.08011683 -0.40631101 -0.56340927\n",
      "  0.12332889 -0.53438875  0.57580776 -0.24328007  0.22807461 -0.10656332\n",
      "  0.60506827  0.33586708 -0.18487633 -0.08919621  0.17831639 -0.13048696\n",
      " -0.15969985 -0.18222192]\n"
     ]
    }
   ],
   "source": [
    "tf_w_data = []\n",
    "tf_idf_data = tf_idf_data.toarray()\n",
    "i = 0\n",
    "for row in splitted:\n",
    "    vec = [0 for i in range(50)]\n",
    "    \n",
    "    temp_tfidf = []\n",
    "    for val in tf_idf_data[i]:\n",
    "        if val != 0:\n",
    "            temp_tfidf.append(val)\n",
    "    \n",
    "    count = 0\n",
    "    tf_idf_sum = 0\n",
    "    for word in row:\n",
    "        try:\n",
    "            count += 1\n",
    "            tf_idf_sum = tf_idf_sum + temp_tfidf[count-1]\n",
    "            vec += (temp_tfidf[count-1] * train_w2v[word])\n",
    "        except:\n",
    "            pass\n",
    "    vec = (float)(1/tf_idf_sum) * vec\n",
    "    tf_w_data.append(vec)\n",
    "    i = i + 1\n",
    "\n",
    "print(tf_w_data[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df2['Summary'], \n",
    "                                                    df2['Score'], \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train first entry:\n",
      "\n",
      " contains MSG\n",
      "\n",
      "\n",
      "X_train shape:  (7500,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train first entry:\\n\\n', X_train.iloc[0])\n",
    "print('\\n\\nX_train shape: ', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Fit the CountVectorizer to the training data\n",
    "vect = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " 'approved',\n",
       " 'bolder',\n",
       " 'charges',\n",
       " 'cornmeal',\n",
       " 'digestive',\n",
       " 'exercise',\n",
       " 'fry',\n",
       " 'haven',\n",
       " 'italy',\n",
       " 'liver',\n",
       " 'mm',\n",
       " 'onions',\n",
       " 'plated',\n",
       " 'receiving',\n",
       " 'seasoned',\n",
       " 'sound',\n",
       " 'target',\n",
       " 'twisted',\n",
       " 'wife']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[::200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3921"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7500x3921 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 28986 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the documents in the training data to a document-term matrix\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6828238587065749\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Predict the transformed test documents\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     0.884400\n",
      "precision_score    0.897603\n",
      "recall_score       0.974456\n",
      "f1_score           0.934452\n",
      "dtype: float64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.39      0.51       386\n",
      "           1       0.90      0.97      0.93      2114\n",
      "\n",
      "    accuracy                           0.88      2500\n",
      "   macro avg       0.82      0.68      0.72      2500\n",
      "weighted avg       0.87      0.88      0.87      2500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 151  235]\n",
      " [  54 2060]]\n"
     ]
    }
   ],
   "source": [
    "metric_bal=pd.Series([metrics.accuracy_score(y_test, predictions),metrics.precision_score(y_test, predictions,average='weighted',labels= [1]),\n",
    "              metrics.recall_score(y_test, predictions,average='weighted',labels= [1]),metrics.f1_score(y_test, predictions,average='weighted',labels= [1])],\n",
    "                     index=['accuracy_score','precision_score','recall_score','f1_score'])\n",
    "print(metric_bal)\n",
    "print()\n",
    "print(metrics.classification_report(y_test, predictions))\n",
    "print()\n",
    "print('Confusion Matrix:')\n",
    "print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6545629678285891\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB().fit(X_train_vectorized, y_train)\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     0.876000\n",
      "precision_score    0.889129\n",
      "recall_score       0.974929\n",
      "f1_score           0.930054\n",
      "dtype: float64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.33      0.45       386\n",
      "           1       0.89      0.97      0.93      2114\n",
      "\n",
      "    accuracy                           0.88      2500\n",
      "   macro avg       0.80      0.65      0.69      2500\n",
      "weighted avg       0.86      0.88      0.86      2500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 129  257]\n",
      " [  53 2061]]\n"
     ]
    }
   ],
   "source": [
    "metric_bal=pd.Series([metrics.accuracy_score(y_test, predictions),metrics.precision_score(y_test, predictions,average='weighted',labels= [1]),\n",
    "              metrics.recall_score(y_test, predictions,average='weighted',labels= [1]),metrics.f1_score(y_test, predictions,average='weighted',labels= [1])],\n",
    "                     index=['accuracy_score','precision_score','recall_score','f1_score'])\n",
    "print(metric_bal)\n",
    "print()\n",
    "print(metrics.classification_report(y_test, predictions))\n",
    "print()\n",
    "print('Confusion Matrix:')\n",
    "print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.5725057720305292\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB().fit(X_train_vectorized, y_train)\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     0.857200\n",
      "precision_score    0.865281\n",
      "recall_score       0.984390\n",
      "f1_score           0.921000\n",
      "dtype: float64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.16      0.26       386\n",
      "           1       0.87      0.98      0.92      2114\n",
      "\n",
      "    accuracy                           0.86      2500\n",
      "   macro avg       0.76      0.57      0.59      2500\n",
      "weighted avg       0.83      0.86      0.82      2500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  62  324]\n",
      " [  33 2081]]\n"
     ]
    }
   ],
   "source": [
    "metric_bal=pd.Series([metrics.accuracy_score(y_test, predictions),metrics.precision_score(y_test, predictions,average='weighted',labels= [1]),\n",
    "              metrics.recall_score(y_test, predictions,average='weighted',labels= [1]),metrics.f1_score(y_test, predictions,average='weighted',labels= [1])],\n",
    "                     index=['accuracy_score','precision_score','recall_score','f1_score'])\n",
    "print(metric_bal)\n",
    "print()\n",
    "print(metrics.classification_report(y_test, predictions))\n",
    "print()\n",
    "print('Confusion Matrix:')\n",
    "print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['gun' 'mega' 'cancelled' 'skimpy' 'skim' 'mention' 'cant' 'signature'\n",
      " 'sickening' 'merchandise']\n",
      "\n",
      "Largest Coefs: \n",
      "['great' 'good' 'the' 'for' 'best' 'and' 'coffee' 'my' 'it' 'love']\n"
     ]
    }
   ],
   "source": [
    "# get the feature names as numpy array\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "# Sort the coefficients from the model\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "# Find the 10 smallest and 10 largest coefficients\n",
    "# The 10 largest coefficients are being indexed using [:-11:-1] \n",
    "# so the list returned is in order of largest to smallest\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\n",
    "vect = TfidfVectorizer(min_df=5).fit(X_train)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6309086720163137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     0.873600\n",
      "precision_score    0.881903\n",
      "recall_score       0.982025\n",
      "f1_score           0.929275\n",
      "dtype: float64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.28      0.41       386\n",
      "           1       0.88      0.98      0.93      2114\n",
      "\n",
      "    accuracy                           0.87      2500\n",
      "   macro avg       0.81      0.63      0.67      2500\n",
      "weighted avg       0.86      0.87      0.85      2500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 108  278]\n",
      " [  38 2076]]\n"
     ]
    }
   ],
   "source": [
    "metric_bal=pd.Series([metrics.accuracy_score(y_test, predictions),metrics.precision_score(y_test, predictions,average='weighted',labels= [1]),\n",
    "              metrics.recall_score(y_test, predictions,average='weighted',labels= [1]),metrics.f1_score(y_test, predictions,average='weighted',labels= [1])],\n",
    "                     index=['accuracy_score','precision_score','recall_score','f1_score'])\n",
    "print(metric_bal)\n",
    "print()\n",
    "print(metrics.classification_report(y_test, predictions))\n",
    "print()\n",
    "print('Confusion Matrix:')\n",
    "print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.5970154558065892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB().fit(X_train_vectorized, y_train)\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     0.870000\n",
      "precision_score    0.871933\n",
      "recall_score       0.991958\n",
      "f1_score           0.928081\n",
      "dtype: float64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.20      0.32       386\n",
      "           1       0.87      0.99      0.93      2114\n",
      "\n",
      "    accuracy                           0.87      2500\n",
      "   macro avg       0.85      0.60      0.63      2500\n",
      "weighted avg       0.86      0.87      0.83      2500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  78  308]\n",
      " [  17 2097]]\n"
     ]
    }
   ],
   "source": [
    "metric_bal=pd.Series([metrics.accuracy_score(y_test, predictions),metrics.precision_score(y_test, predictions,average='weighted',labels= [1]),\n",
    "              metrics.recall_score(y_test, predictions,average='weighted',labels= [1]),metrics.f1_score(y_test, predictions,average='weighted',labels= [1])],\n",
    "                     index=['accuracy_score','precision_score','recall_score','f1_score'])\n",
    "print(metric_bal)\n",
    "print()\n",
    "print(metrics.classification_report(y_test, predictions))\n",
    "print()\n",
    "print('Confusion Matrix:')\n",
    "print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6826669967304082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB().fit(X_train_vectorized, y_train)\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     0.871600\n",
      "precision_score    0.898622\n",
      "recall_score       0.956008\n",
      "f1_score           0.926427\n",
      "dtype: float64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.41      0.50       386\n",
      "           1       0.90      0.96      0.93      2114\n",
      "\n",
      "    accuracy                           0.87      2500\n",
      "   macro avg       0.76      0.68      0.71      2500\n",
      "weighted avg       0.86      0.87      0.86      2500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 158  228]\n",
      " [  93 2021]]\n"
     ]
    }
   ],
   "source": [
    "metric_bal=pd.Series([metrics.accuracy_score(y_test, predictions),metrics.precision_score(y_test, predictions,average='weighted',labels= [1]),\n",
    "              metrics.recall_score(y_test, predictions,average='weighted',labels= [1]),metrics.f1_score(y_test, predictions,average='weighted',labels= [1])],\n",
    "                     index=['accuracy_score','precision_score','recall_score','f1_score'])\n",
    "print(metric_bal)\n",
    "print()\n",
    "print(metrics.classification_report(y_test, predictions))\n",
    "print()\n",
    "print('Confusion Matrix:')\n",
    "print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest tfidf:\n",
      "['ounce' 'wheat' 'dairy' 'getting' 'ate' 'products' 'teeth' 'being' 'feel'\n",
      " 'once']\n",
      "\n",
      "Largest tfidf: \n",
      "['yummy' 'horrible' 'house' 'huge' 'in' 'interesting' 'is' 'island' 'it'\n",
      " 'its']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
    "\n",
    "print('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\n",
    "print('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['waste' 'disgusting' 'disapointed' 'nasty' 'control' 'warning' 'yuck'\n",
      " 'yuk' 'horrible' 'sorry']\n",
      "\n",
      "Largest Coefs: \n",
      "['great' 'good' 'the' 'for' 'best' 'and' 'coffee' 'my' 'it' 'love']\n"
     ]
    }
   ],
   "source": [
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1347"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the CountVectorizer to the training data specifiying a minimum \n",
    "# document frequency of 5 and extracting 1-grams and 2-grams\n",
    "vect = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n",
    "\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.6876559428630251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     0.887200\n",
      "precision_score    0.898955\n",
      "recall_score       0.976348\n",
      "f1_score           0.936054\n",
      "dtype: float64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.40      0.52       386\n",
      "           1       0.90      0.98      0.94      2114\n",
      "\n",
      "    accuracy                           0.89      2500\n",
      "   macro avg       0.83      0.69      0.73      2500\n",
      "weighted avg       0.88      0.89      0.87      2500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 154  232]\n",
      " [  50 2064]]\n"
     ]
    }
   ],
   "source": [
    "metric_bal=pd.Series([metrics.accuracy_score(y_test, predictions),metrics.precision_score(y_test, predictions,average='weighted',labels= [1]),\n",
    "              metrics.recall_score(y_test, predictions,average='weighted',labels= [1]),metrics.f1_score(y_test, predictions,average='weighted',labels= [1])],\n",
    "                     index=['accuracy_score','precision_score','recall_score','f1_score'])\n",
    "print(metric_bal)\n",
    "print()\n",
    "print(metrics.classification_report(y_test, predictions))\n",
    "print()\n",
    "print('Confusion Matrix:')\n",
    "print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7277452071313376\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB().fit(X_train_vectorized, y_train)\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     0.878000\n",
      "precision_score    0.913580\n",
      "recall_score       0.945128\n",
      "f1_score           0.929086\n",
      "dtype: float64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.51      0.56       386\n",
      "           1       0.91      0.95      0.93      2114\n",
      "\n",
      "    accuracy                           0.88      2500\n",
      "   macro avg       0.77      0.73      0.75      2500\n",
      "weighted avg       0.87      0.88      0.87      2500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 197  189]\n",
      " [ 116 1998]]\n"
     ]
    }
   ],
   "source": [
    "metric_bal=pd.Series([metrics.accuracy_score(y_test, predictions),metrics.precision_score(y_test, predictions,average='weighted',labels= [1]),\n",
    "              metrics.recall_score(y_test, predictions,average='weighted',labels= [1]),metrics.f1_score(y_test, predictions,average='weighted',labels= [1])],\n",
    "                     index=['accuracy_score','precision_score','recall_score','f1_score'])\n",
    "print(metric_bal)\n",
    "print()\n",
    "print(metrics.classification_report(y_test, predictions))\n",
    "print()\n",
    "print('Confusion Matrix:')\n",
    "print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7058372262881064\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB().fit(X_train_vectorized, y_train)\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score     0.869600\n",
      "precision_score    0.906733\n",
      "recall_score       0.942763\n",
      "f1_score           0.924397\n",
      "dtype: float64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.47      0.53       386\n",
      "           1       0.91      0.94      0.92      2114\n",
      "\n",
      "    accuracy                           0.87      2500\n",
      "   macro avg       0.75      0.71      0.73      2500\n",
      "weighted avg       0.86      0.87      0.86      2500\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 181  205]\n",
      " [ 121 1993]]\n"
     ]
    }
   ],
   "source": [
    "metric_bal=pd.Series([metrics.accuracy_score(y_test, predictions),metrics.precision_score(y_test, predictions,average='weighted',labels= [1]),\n",
    "              metrics.recall_score(y_test, predictions,average='weighted',labels= [1]),metrics.f1_score(y_test, predictions,average='weighted',labels= [1])],\n",
    "                     index=['accuracy_score','precision_score','recall_score','f1_score'])\n",
    "print(metric_bal)\n",
    "print()\n",
    "print(metrics.classification_report(y_test, predictions))\n",
    "print()\n",
    "print('Confusion Matrix:')\n",
    "print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['disapointed' 'what happened' 'not good' 'don waste' 'warning'\n",
      " 'poor quality' 'disgusting' 'nasty' 'of money' 'bad batch']\n",
      "\n",
      "Largest Coefs: \n",
      "['great' 'good' 'the' 'for' 'best' 'and' 'coffee' 'my' 'it' 'love']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
